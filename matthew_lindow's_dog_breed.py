# -*- coding: utf-8 -*-
"""Matthew_Lindow's_Dog_Breed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bO7FsfmDKrUHn-C2NMFjFLdz5uJpD5Ly

# Kaggle Competition - Dog Breed Identifcation
### Matthew Lindow
#### A01875594
Determine the breed of a dog in an image

https://www.kaggle.com/c/dog-breed-identification/
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import pandas as pd
import math
import io
import os
import shutil
import time
from copy import deepcopy
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import random_split
import torch.utils.data as data

device = 'cuda'

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

from google.colab import files
uploaded = files.upload()

labels = pd.read_csv(io.BytesIO(uploaded['labels.csv']))

# !unzip /content/gdrive/MyDrive/test.zip -d /content/gdrive/MyDrive/test
# !unzip /content/gdrive/MyDrive/train.zip -d /content/gdrive/MyDrive/train

transform = transforms.Compose(
    [transforms.RandomHorizontalFlip(),
     transforms.RandomRotation(20),
     transforms.Resize(size=(150,150)),
     transforms.ColorJitter(hue=.001, saturation=.001),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 32

train_data_path = "/content/gdrive/MyDrive/train"
test_data_path = "/content/gdrive/MyDrive/test"

train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)
testset = torchvision.datasets.ImageFolder(root=test_data_path, transform=transform)
quarter = len(train_data) // 4
trainset, valset = random_split(train_data, [len(train_data) - quarter, quarter])

valloader = data.DataLoader(valset, batch_size=batch_size, shuffle=True,  num_workers=4)
trainloader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True,  num_workers=4)
testloader = data.DataLoader(testset, batch_size=batch_size, shuffle=True,  num_workers=4)

print("Number of train samples: ", len(trainset))
print("Number of validation samples: ", len(valset))
print("Number of test samples: ", len(testset))

# labels.head()
classes = labels['breed'].to_list()
print("Number of breeds: ", len(classes))

import matplotlib.pyplot as plt

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))

import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models

net = models.resnet34(pretrained=True).to(device)

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# best_val_acc = -1000
# best_val_model = None
# for epoch in range(10):  
#     net.train()
#     running_loss = 0.0
#     running_acc = 0
#     for i, data in enumerate(trainloader, 0):
#         inputs, labels = data
#         inputs, labels = inputs.cuda(),labels.cuda()
# 
#         optimizer.zero_grad()
#         outputs = net(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()
# 
#         # print statistics
#         running_loss += loss.item() * inputs.size(0)
#         out = torch.argmax(outputs.detach(),dim=1)
#         assert out.shape==labels.shape
#         running_acc += (labels==out).sum().item()
#     print(f"Train loss {epoch+1}: {running_loss/len(trainset)},Train Acc:{running_acc*100/len(trainset)}%")
#     
#     correct = 0
#     net.eval()
#     with torch.no_grad():
#         for inputs,labels in valloader:
#             out = net(inputs.cuda()).cpu()
#             out = torch.argmax(out,dim=1)
#             acc = (out==labels).sum().item()
#             correct += acc
#     print(f"Val accuracy:{correct*100/len(valset)}%")
#     if correct>best_val_acc:
#         best_val_acc = correct
#         best_val_model = deepcopy(net.state_dict())
#     lr_scheduler.step()
#     if running_acc*100/len(trainset) == float(100) and correct*100/len(valset) == float(100):
#       break
#     
# print('Finished Training')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# correct = 0
# net.load_state_dict(best_val_model)
# net.eval()
# with torch.no_grad():
#     for inputs,labels in testloader:
#         out = net(inputs.cuda()).cpu()
#         out = torch.argmax(out,dim=1)
#         acc = (out==labels).sum().item()
#         
#         correct += acc
# print(f"Test accuracy: {correct*100/len(testset)}%")